Q-Learning
Q-Learning - Steps/Actions to Reach Terminal State - 250 Iterations
679,437,1248,303,181,176,216,148,183,306,126,159,134,135,297,172,199,68,61,169,113,73,45,112,41,195,123,82,49,36,60,113,38,63,46,37,398,49,35,72,151,61,31,32,65,49,77,28,40,42,35,100,35,77,115,60,71,41,72,52,62,45,129,53,48,46,64,32,53,31,37,46,72,53,47,45,51,58,52,41,46,32,68,44,59,53,57,38,196,71,37,108,80,92,62,89,59,43,53,61,191,47,306,63,66,46,36,39,32,35,42,94,63,45,33,32,40,39,46,40,43,67,37,45,58,46,58,57,37,70
Q-Learning - Time Required to Run Algorithm - 250 Iterations
86,32,29,23,7,10,19,10,12,18,15,10,20,11,14,33,33,18,16,13,14,20,12,13,12,19,42,34,46,15,17,18,15,16,12,18,17,18,16,19,16,19,19,48,51,54,48,44,42,17,15,17,15,17,14,15,19,15,17,16,18,17,17,17,18,18,21,20,17,21,16,25,51,53,58,56,54,44,17,20,19,22,19,19,18,27,22,21,25,23,22,23,24,27,25,32,22,23,22,22,24,23,28,23,24,69,73,75,68,60,63,87,31,30,30,25,24,24,23,31,26,24,23,26,25,29,26,29,25,24
Q-Learning - Reward Gained - 250 Iterations
-577.0,-335.0,-1146.0,-201.0,-79.0,-74.0,-114.0,-46.0,-81.0,-204.0,-24.0,-57.0,-32.0,-33.0,-195.0,-70.0,-97.0,34.0,41.0,-67.0,-11.0,29.0,57.0,-10.0,61.0,-93.0,-21.0,20.0,53.0,66.0,42.0,-11.0,64.0,39.0,56.0,65.0,-296.0,53.0,67.0,30.0,-49.0,41.0,71.0,70.0,37.0,53.0,25.0,74.0,62.0,60.0,67.0,2.0,67.0,25.0,-13.0,42.0,31.0,61.0,30.0,50.0,40.0,57.0,-27.0,49.0,54.0,56.0,38.0,70.0,49.0,71.0,65.0,56.0,30.0,49.0,55.0,57.0,51.0,44.0,50.0,61.0,56.0,70.0,34.0,58.0,43.0,49.0,45.0,64.0,-94.0,31.0,65.0,-6.0,22.0,10.0,40.0,13.0,43.0,59.0,49.0,41.0,-89.0,55.0,-204.0,39.0,36.0,56.0,66.0,63.0,70.0,67.0,60.0,8.0,39.0,57.0,69.0,70.0,62.0,63.0,56.0,62.0,59.0,35.0,65.0,57.0,44.0,56.0,44.0,45.0,65.0,32.0

Value Iteration
Value Iteration - Steps/Actions to Reach Terminal State - 80 Iterations
3188,37056,3006,835,5822,3740,4592,2037,687,201,298,81,34,31,34,34,33,36,32,30,38,28,30,30,42,26,37,30,36,34,34,29,39,32,38,30,37,31,33,31
Value Iteration - Time Required to Run Algorithm - 80 Iterations
42,2,2,2,2,3,4,4,4,5,4,5,6,6,6,6,7,8,9,8,15,22,23,21,22,22,23,23,25,26,26,28,30,13,14,14,14,14,15,15
Value Iteration - Reward Gained - 80 Iterations
-3086.0,-36954.0,-2904.0,-733.0,-5720.0,-3638.0,-4490.0,-1935.0,-585.0,-99.0,-196.0,21.0,68.0,71.0,68.0,68.0,69.0,66.0,70.0,72.0,64.0,74.0,72.0,72.0,60.0,76.0,65.0,72.0,66.0,68.0,68.0,73.0,63.0,70.0,64.0,72.0,65.0,71.0,69.0,71.0

Policy Iteration
Policy Iteration - Steps/Actions to Reach Terminal State - 80 Iterations
38489,894992,15136,6483,7460,150433,7355,31488,657,882,459,799,61773,188,38,34,32,37,33,34,35,29,29,36,34,31,29,30,32,29,37,29,28,27,32,38,29,28,34,26
Policy Iteration - Time Required to Run Algorithm - 80 Iterations
51,7,4,4,5,6,7,8,8,9,9,11,11,11,11,12,12,14,15,90,18,18,19,18,17,19,20,21,23,26,29,28,104,26,26,26,27,28,28,31
Policy Iteration - Reward Gained - 80 Iterations
-38387.0,-894890.0,-15034.0,-6381.0,-7358.0,-150331.0,-7253.0,-31386.0,-555.0,-780.0,-357.0,-697.0,-61671.0,-86.0,64.0,68.0,70.0,65.0,69.0,68.0,67.0,73.0,73.0,66.0,68.0,71.0,73.0,72.0,70.0,73.0,65.0,73.0,74.0,75.0,70.0,64.0,73.0,74.0,68.0,76.0
